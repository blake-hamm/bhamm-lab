{{- if and .Values.postgresql.backups.enabled .Values.postgresql.restore.enabled }}
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Values.name }}-bucket-prep
  namespace: {{ .Values.name }}
  annotations:
    argocd.argoproj.io/sync-wave: "16"
    argocd.argoproj.io/hook: "Sync"
    argocd.argoproj.io/hook-delete-policy: HookFailed
spec:
  template:
    spec:
      restartPolicy: Never
      serviceAccountName: {{ .Values.name }}-bucket-manager
      containers:
        - name: bucket-manager
          image: amazon/aws-cli:2.15.17
          command: ["/bin/sh", "-c"]
          args:
            - |
              set -euo pipefail

              echo "Starting bucket preparation for CNPG deployment..."

              # Configuration
              BUCKET_NAME="${BUCKET_NAME}"
              SOURCE_PATH="{{ .Values.name }}-postgresql"
              LATEST_PATH="{{ .Values.name }}-postgresql-latest"
              ENDPOINT_URL="${S3_ENDPOINT_URL}"

              # Configure AWS CLI for SeaweedFS
              aws configure set aws_access_key_id "${AWS_ACCESS_KEY_ID}"
              aws configure set aws_secret_access_key "${AWS_SECRET_ACCESS_KEY}"
              aws configure set region "${AWS_DEFAULT_REGION:-us-east-1}"

              echo "Configured AWS CLI for SeaweedFS endpoint: ${ENDPOINT_URL}"
              echo "Working with bucket: ${BUCKET_NAME}"
              echo "Source path: ${SOURCE_PATH}"
              echo "Latest path: ${LATEST_PATH}"

              # Function to check if bucket exists
              bucket_exists() {
                aws s3api head-bucket --bucket "$1" --endpoint-url="${ENDPOINT_URL}" >/dev/null 2>&1
              }

              # Function to check if path has content in bucket
              path_has_content() {
                local count=$(aws s3 ls s3://"${BUCKET_NAME}"/"$1"/ --endpoint-url="${ENDPOINT_URL}" --recursive | wc -l)
                [ "$count" -gt 0 ]
              }

              # Function to get object count in path
              get_object_count() {
                aws s3 ls s3://"${BUCKET_NAME}"/"$1"/ --endpoint-url="${ENDPOINT_URL}" --recursive | wc -l
              }

              # Step 1: Ensure the bucket exists
              if ! bucket_exists "${BUCKET_NAME}"; then
                echo "ERROR: Bucket ${BUCKET_NAME} doesn't exist, cannot proceed"
                exit 1
              fi

              # Step 2: Clear out the latest path (create if it doesn't exist)
              if path_has_content "${LATEST_PATH}"; then
                echo "Latest path ${LATEST_PATH} exists with content, clearing it..."
                aws s3 rm s3://"${BUCKET_NAME}"/"${LATEST_PATH}"/ --endpoint-url="${ENDPOINT_URL}" --recursive || true
                echo "Latest path cleared."
              else
                echo "Latest path ${LATEST_PATH} doesn't exist or is empty, ready to use."
              fi

              # Step 3: Check if source path exists and has content
              if path_has_content "${SOURCE_PATH}"; then
                echo "Source path ${SOURCE_PATH} has content, copying to ${LATEST_PATH}..."

                # Copy all objects from source path to latest path
                aws s3 sync s3://"${BUCKET_NAME}"/"${SOURCE_PATH}"/ s3://"${BUCKET_NAME}"/"${LATEST_PATH}"/ \
                  --endpoint-url="${ENDPOINT_URL}"

                echo "Copy completed. Verifying..."

                # Verify the copy was successful
                SOURCE_COUNT=$(get_object_count "${SOURCE_PATH}")
                LATEST_COUNT=$(get_object_count "${LATEST_PATH}")

                if [ "$SOURCE_COUNT" -ne "$LATEST_COUNT" ]; then
                  echo "ERROR: Copy verification failed. Source: $SOURCE_COUNT objects, Latest: $LATEST_COUNT objects"
                  exit 1
                fi

                echo "Copy verified successfully. $SOURCE_COUNT objects copied."
              else
                echo "ERROR: Source path ${SOURCE_PATH} has no content, cannot restore"
                exit 1
              fi

              # Step 4: Clear the source path
              echo "Clearing source path ${SOURCE_PATH}..."
              aws s3 rm s3://"${BUCKET_NAME}"/"${SOURCE_PATH}"/ --endpoint-url="${ENDPOINT_URL}" --recursive || true

              # Step 5: Verify source path is empty
              if path_has_content "${SOURCE_PATH}"; then
                echo "ERROR: Failed to completely clear source path"
                exit 1
              fi

              echo "Source path ${SOURCE_PATH} is now empty and ready for CNPG"
              echo "Backup data is safely stored in ${LATEST_PATH}"
              echo "Bucket preparation completed successfully!"
          env:
            - name: BUCKET_NAME
              value: "cnpg-backups"
            - name: S3_ENDPOINT_URL
              value: "http://seaweedfs-s3.seaweedfs.svc.cluster.local:8333"
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: cnpg-s3-backup-creds
                  key: access_key
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: cnpg-s3-backup-creds
                  key: secret_key
            - name: AWS_DEFAULT_REGION
              value: "us-east-1"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Values.name }}-bucket-manager
  namespace: {{ .Values.name }}
  annotations:
    argocd.argoproj.io/sync-wave: "14"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: {{ .Values.name }}-bucket-manager
  namespace: {{ .Values.name }}
  annotations:
    argocd.argoproj.io/sync-wave: "14"
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: {{ .Values.name }}-bucket-manager
  namespace: {{ .Values.name }}
  annotations:
    argocd.argoproj.io/sync-wave: "15"
subjects:
- kind: ServiceAccount
  name: {{ .Values.name }}-bucket-manager
  namespace: {{ .Values.name }}
roleRef:
  kind: Role
  name: {{ .Values.name }}-bucket-manager
  apiGroup: rbac.authorization.k8s.io
{{- end }}