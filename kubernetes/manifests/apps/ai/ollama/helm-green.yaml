apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ollama
  namespace: argocd
  annotations:
    argocd.argoproj.io/sync-wave: "24"
spec:
  destination:
    namespace: ollama
    server: https://kubernetes.default.svc
  project: default
  source:
    chart: ollama
    repoURL: https://otwld.github.io/ollama-helm
    targetRevision: 1.32.0
    helm:
      valuesObject:
        image:
          repository: ghcr.io/rjmalagon/ollama-linux-amd-apu
          tag: "rocm-6.4.3-latest"
        knative:
          enabled: false
        ollama:
          gpu:
            enabled: true
            draEnabled: false
            type: 'amd'
            number: 1
          models:
            # -- List of models to pull at container startup
            # The more you add, the longer the container will take to start if models are not present
            # pull:
            #  - llama2
            #  - mistral
            pull: []
            # -- List of models to load in memory at container startup
            # run:
            #  - llama2
            #  - mistral
            run: []
            # -- List of models to create at container startup, there are two options
            # 1. Create a raw model
            # 2. Load a model from configMaps, configMaps must be created before and are loaded as volume in "/models" directory.
            # create:
            #  - name: llama3.1-ctx32768
            #    configMapRef: my-configmap
            #    configMapKeyRef: configmap-key
            #  - name: llama3.1-ctx32768
            #    template: |
            #      FROM llama3.1
            #      PARAMETER num_ctx 32768
            create: []
            # -- Automatically remove models present on the disk but not specified in the values file
            clean: false
        persistentVolume:
          enabled: true
          existingClaim: "ollama-data"
        nodeSelector:
          feature.node.kubernetes.io/amd-gpu: "true"
        tolerations:
          - key: "amd.com/gpu"
            operator: "Exists"
            effect: "NoSchedule"
        resources:
          requests:
            memory: 12Gi
            cpu: 2000m
          limits:
            memory: 20Gi
            cpu: 4000m
        extraEnv:
          - name: HSA_OVERRIDE_GFX_VERSION
            value: 11.5.1
          - name: HCC_AMDGPU_TARGET
            value: gfx1151
          - name: HSA_ENABLE_SDMA
            value: "0"
          - name: OLLAMA_DEBUG
            value: "1"
          - name: OLLAMA_AMD_USE_VRAM
            value: "1"
          - name: OLLAMA_AMD_DISABLE_GTT
            value: "1"
          - name: OLLAMA_AMD_FORCE_DISCRETE
            value: "1"
          - name: OLLAMA_LOW_VRAM_THRESHOLD
            value: "0"
  syncPolicy:
    syncOptions:
      - ApplyOutOfSyncOnly=true
      - CreateNamespace=true
    automated:
      prune: true
      selfHeal: true
    retry:
      limit: 10
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 10m
